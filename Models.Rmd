---
title: "Untitled"
author: "Anne Valder"
date: "2/12/2022"
output: html_document
---
TO DO: runterschreiben was wie und dann seh ich welche Modelle... 

Models I have:

- AR(1) and standard OLS (split data IS and OOS) (6x)
- AR(1) and expanding estimation  (IS and OOS) (6x) - cannot compare to others sample set, correct since incorporate prediction in new train data?
- auto.arima model (lag selection automatic, and 4 (still have to do)) used test and train, explanation on pacf..)
- VAR model (lag selection automatic (and pacf and acf), and 4)

TO DO: 

- forecast aus expanding
- VAR mit test and train!!!! done
- VAR mit expanding... done
- tests on other models as well....! 
- overview of results...! tables
- Do new model with consumer Google index statt economic Google index? - initialize new indices..

Question: 
- incorporate further data or not? 
- is expanding window correct?

goal which is best at forecasting GDP! (measured by out of sample accuracy)

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# libraries

```{r, include=FALSE}
library(readr)
library(readxl)
library(dplyr)
library(tidyverse)
library(ggplot2)
library(tseries)
library(forecast)
library(vars)
library(GGally)
library(Metrics)
library(caret)
library(collapse)
library(urca)
```


```{r}
rm(list=ls())
getwd()
```
# Load all data in (GDP, CCI, Goolge), extension unemployment (statAT), inflation(statAT), uncertainty index (paper Brown et al)

#GDP
```{r}
t_0 <- as.Date("2006-01-01") #Setting start date for the series
t_1 <- as.Date("2021-07-01") #Setting end date for the series
t_2 <- as.Date("2021-12-31")
Date_q <- seq.Date(t_0,t_1,by="quarter")
Date_m <- seq.Date(t_0,t_2,by="month")

bigT <- length(Date_q)
M <- 6
Data   <- matrix(NA,bigT,M)
colnames(Data)  <- c("gdp", "cci", "google","gdp_ts", "cci_ts", "google_ts") 
Data <- as.data.frame(Data)
rownames(Data)  <- as.Date(Date_q)
```


```{r}
# abgerufen final am 11.02.2022
#Source: https://data.oecd.org/gdp/quarterly-gdp.htm#indicator-chart
gdp <- read.csv("https://raw.githubusercontent.com/anneval/MA_data/main/RData/GDP_oecd.csv")[9:71,6:7]

colnames(gdp)[colnames(gdp) %in% c("TIME", "Value")] <- c("QDate", "value")
gdp <- cbind(gdp,Date_q)
#ts:
gdp_ts <- ts(gdp$value, start=c(2006,1), end = c(2021,3), frequency = 4)

Data[(Date_q%in%gdp$Date_q),1] <- gdp$value
Data$gdp_ts <- ts(Data$gdp, start=c(2006,1), end = c(2021,3), frequency = 4)
```
#CCI
```{r, include=FALSE}
# abgerufen final am 11.02.2022
#Source: https://ec.europa.eu/info/business-economy-euro/indicators-statistics/economic-databases/business-and-consumer-surveys/download-business-and-consumer-survey-data/time-series_en#consumers

cci <- read.csv2("https://raw.githubusercontent.com/anneval/MA_data/main/RData/CCI.csv")[253:444,c(1,297)]

colnames(cci)[colnames(cci) %in% c("X", "CONS.AT.TOT.COF.BS.M")] <- c("time", "value")
cci <- cbind(cci,Date_m)
cci <- arrange(cci, Date_m)
cci$Date_q <- as.yearqtr(cci$Date_m) 
cci$Date_q <- as.Date(cci$Date_q)

#cci$Date_q  <- as.character(cci$Date_m)
#cci$Date_q[CCI_mntly$Date_q == "2021 Q4"] <- "2021 Q3"

cci_qtrly <- cci %>% group_by(Date_q) %>%
  summarise_all(mean)

cci_qtrly_63 <- cci_qtrly[1:63,]
Data[(Date_q%in%cci_qtrly_63$Date_q),2] <- (cci_qtrly_63$value)
Data$cci_ts <- ts(Data$cci, start=c(2006,1), end = c(2021,3), frequency = 4)

```

# Google
```{r}
# abgerufen: daily update
Google_AT_daily <- read.csv("https://raw.githubusercontent.com/anneval/MA_data/main/raw/at/trendecon_sa.csv")

# transform to quarterly and then do ts:
Google_AT_daily$time <- as.Date(Google_AT_daily$time)
Google_AT_daily <- arrange(Google_AT_daily, time)
Google_AT_daily$Date_q <- as.yearqtr(Google_AT_daily$time)
Google_AT_daily$Date_q <- as.Date(Google_AT_daily$Date_q)
#Google_AT_daily$QDate  <- as.character(Google_AT_daily$QDate)
#Google_AT_daily$QDate[Google_AT_daily$QDate == "2022 Q1"] <- "2021 Q3"  
#Google_AT_daily$QDate[Google_AT_daily$QDate == "2021 Q4"] <- "2021 Q3"  
Google_AT_qtrly <- Google_AT_daily %>% group_by(Date_q) %>%
  summarise_all(mean)

#rownames(Google_AT_qtrly)  <- as.Date(Date_q)
Google_AT_qtrly_63 <- Google_AT_qtrly[1:63,]
Data[(Date_q%in%Google_AT_qtrly_63$Date_q),3] <- (Google_AT_qtrly_63$value)
Data$google_ts <- ts(Data$google, start=c(2006,1), end = c(2021,3), frequency = 4)
```

# Graphics
```{r}
par(mfrow = c(3,1))

# GDP

ggplot(gdp, aes(x=Date_q, y=value,col = variable)) +
  geom_line(color = "steelblue") +
  theme_light() +
  labs(title = "Quarterly GDP Growth Rate (Q1 2006 - Q3 2021)", x = "Years", y = "Austria's GDP growth (in%)")+
  theme(plot.title = element_text(hjust = 0.5, face ="bold")) +
  scale_x_date(date_labels="%b %y",date_breaks  ="24 month")
  

#CCI

ggplot(cci, aes(x=Date_m, y=value)) +
  geom_line(color = "steelblue") +
  theme_light() +
    labs(title = "Consumer Confidence Austria 2006-2021 (Monthly)", x = "Years", y = "Austria's Consumer Confidence (total)")+
  theme(plot.title = element_text(hjust = 0.5, face ="bold")) +
  scale_x_date(date_labels="%b %y",date_breaks  ="24 month")

# PES - Google

ggplot(Google_AT_daily, aes(x=time, y=value)) +
  geom_line(color = "black") +
  theme_light() +
    labs(title = "Google Trends TrendEcon Daily Indicator AT (2006 - 2021)", x = "Years", y = "Austria's GT daily")+
  theme(plot.title = element_text(hjust = 0.5, face ="bold")) +
  scale_x_date(date_labels="%b %y",date_breaks  ="24 month")
```

#later graph comparison
```{r}
##### Abilene für comparison abbilden 
ts.plot(ts(Data[,1],frequency = 4, start = c(2006,1)),
          ts(Data[,3],frequency = 4, start = c(2006,1)),
          ts(CCI_qtrlyx$Value,frequency = 4, start = c(2006,1)),
    col = c("red", "blue","black"),
    xlab = "Year", 
    ylab = "Search Frequency (Wirtschaftskrise)", 
    lwd = 1)
legend("bottomright", c("GDP growth", "PES","CCI"), col=c("red","blue", "black"), lty=c(1),
       inset=c(0,1), xpd=TRUE, horiz=TRUE, bty="n"
       )

## with growth rates of cci...
ts.plot(ts(Data[,1],frequency = 4, start = c(2006,1)),
          ts(Data[,3],frequency = 4, start = c(2006,1)),
          ts(cci_gr$cci_gr,frequency = 4, start = c(2006,1)),
    col = c("red", "blue","black"),
    xlab = "Year", 
    ylab = "Search Frequency (Wirtschaftskrise)", 
    lwd = 1)
legend("bottomright", c("GDP growth", "PES","CCI"), col=c("red","blue", "black"), lty=c(1),
       inset=c(0,1), xpd=TRUE, horiz=TRUE, bty="n"
       )


cci_gr <- ((cci_qtrly$value - lag(cci_qtrly$value))/lag(cci_qtrly$value))  
cci_gr <- as.data.frame(cci_gr)
cci_gr[2:64,]
```


# dataframe for later models 
```{r}
Data_Var <- Data[,1:3]
Data$gdp_lag <- lag(Data$gdp)
```


#ADF tests: 
```{r}
adfgdp <- adf.test(Data$gdp) # stationary
adfcci <- adf.test(Data$cci) # stationary
adfgoogle <- adf.test(Data$google) # not stat # test agao  after remove inlation 
# not stationary since I included inflation... 
adfgdp
adfcci
adfgoogle

adfgdpdiff <- adf.test(diff(Data$gdp))
adf.test(diff(Data$cci))
adf.test(diff(Data$google))

remotes::install_github("fcbarbi/macroR")
library(macror)

x<-urTable(Data[,1:3], tests = c("adf", "pp", "kpss"), order = 1, file = NULL,
format="latex")

library(xtable)
print(xtable(x, type = "latex"), file = "stattests.tex")

```
kss tests and phillip peron tests:
```{r}
kpss.test(Data$gdp) # stationary
kpss.test(Data$cci) # not stationary at 5%...0.09
kpss.test(Data$google) # stationary

pp.test(Data$gdp) # stationary
pp.test(Data$cci) # not stationary (0.21)
pp.test(Data$google) # stationary

# Johansen test  -dont need to not integrated  ofsame orders!!!
#(https://stats.stackexchange.com/questions/301483/cointegration-if-both-variables-are-i0)
# The null hypothesis for both forms of test is that there are no cointegrating equations.
#Johansen’s test is a way to determine if three or more time series are cointegrated. More specifically, it assesses the validity of a cointegrating relationship, using a maximum likelihood estimates (MLE) approach. It is also used to find the number of relationships and as a tool to estimating those relationships (Wee & Tan, 1997).
jotest=ca.jo(Data[,1:3], type="trace", K=2, ecdet="none", spec="longrun")
summary(jotest)

s = 1.000*Data[,1] - 0.02765629*Data[,2]  -0.17006873*Data[,3]
plot(s, type="l")
adf.test(s)


mod6<- lm(gdp ~ cci, data = Data)

adf.test(mod6$residuals, k=1) # stationarity true, have a cointegrated pair.. 


```
# ACF and PACF plots: Reasoning stationarity
```{r}
par(mfrow = c(3,1))
acf(Data$gdp)
acf(Data$cci)
acf(Data$google)

par(mfrow = c(3,))
pacf(Data$gdp)
pacf(Data$cci)
pacf(Data$google)
```
# Correlations
```{r}
ggpairs(Data[,1:3])
```

#### Models - simple first later expanding? (and CV, robustness)

```{r}
Data_train <- Data[1:44,] # 70%
Data_test <- Data[45:63,] #30%
```

# Models Heik:

AR(1)
Model 1: $GDP_t = \beta_0 +\beta_1 GDP_{t-1} + \epsilon_t  \qquad  t =1,\dotsc,T$

```{r}
mod1 <- lm(gdp ~ lag(gdp), data = Data_train)
summary(mod1)
sqrt(mean(mod1$residuals^2)) # IS 
forecast::accuracy(mod1)

pred_mod1 <- predict(mod1, Data_test)
pred_mod1
acc_oss <-forecast::accuracy(Data_test$gdp,pred_mod1)
acc_oss

forecast_mod1 <- predict(mod1, n.ahead = 3)



#plot(forecast_mod1)
```
Model 2:  $GDP_t = \beta_0 +\beta_1 CCI_{t} +\epsilon_t \qquad  t =1,\dotsc,T$
```{r}

#Data_cci <- cci_qtrly[,c(1,3)]
#colnames(Data_cci) <- c("time", "cci") kann forecasten mit dereinen observation mehr aber kann nicht evaluaten... no equivalent gdp value

mod2 <- lm(gdp ~ cci, data = Data_train)
summary(mod2)
sqrt(mean(mod2$residuals^2)) # IS 
forecast::accuracy(mod2)
#pred_mod2
pred_mod2 <- predict(mod2,Data_test)
ts.plot(pred_mod2)
#fore <- predict(mod2,newdata = Data_cci) # predict cci ...

acc_oss <-forecast::accuracy(Data_test$gdp,pred_mod2)
acc_oss
#pred_test <- predict(mod2, cci_test)
#mod2$coefficients

```
Model 3:  $GDP_t = \beta_0 +\beta_1 GT_{t,i} +\epsilon_t \qquad  t =1,\dotsc,T \qquad  n =1,\dotsc,N$

```{r}
# do new data set where google all periods
#colnames(Google_AT_qtrly) <- c("Date_q","time","google")
Data_google <- Google_AT_qtrly[,c(1,3)]
colnames(Data_google) <- c("time", "google")

mod3<- lm(gdp ~ google, data = Data_train)
summary(mod3)
sqrt(mean(mod3$residuals^2)) # IS 
forecast::accuracy(mod3) # IS accuracy

pred_mod3 <- predict(mod3, Data_test)
#pred_mod3 <- predict(mod3, Google_AT_qtrly[45:65,])
pred_mod3

acc_oss <-forecast::accuracy(Data_test$gdp,pred_mod3)
acc_oss

fore <- predict(newdata = Data_google,mod3)

ts.plot(fore)
ts.plot(Google_AT_qtrly$value)
```
Model 4: $GDP_t = \beta_0 +\beta_1 GDP_{t-1} + \beta_2 CCI_{t} + \epsilon_t \qquad  t =1,\dotsc,T$

```{r}
mod4<- lm(gdp ~ lag(gdp) + cci, data = Data_train)
summary(mod4)
sqrt(mean(mod4$residuals^2)) # IS 
forecast::accuracy(mod4) # IS accuracy

pred_mod4 <- predict(mod4, Data_test)
pred_mod4

acc_oss <-forecast::accuracy(Data_test$gdp,pred_mod4)
acc_oss
```
Model 5: $GDP_t = \beta_0 +\beta_1 GDP_{t-1} + \beta_2 GT_{t,i} + \epsilon_t \qquad  t =1,\dotsc,T \qquad  n =1,\dotsc,N$

```{r}
mod5<- lm(gdp ~ lag(gdp) + google, data = Data_train)
summary(mod5)
sqrt(mean(mod5$residuals^2)) # IS 
forecast::accuracy(mod5) # IS accuracy

pred_mod5 <- predict(mod5, Data_test)
acc_oos5 <-forecast::accuracy(Data_test$gdp,pred_mod5)
acc_oos5

# test stimmt!
#error <- Data_test$gdp - pred_mod5
#error <-error[!is.na(error)]
#RMSE <- sqrt(mean(error^2))
#RMSE
```

Model 6: $GDP_t = \beta_0 +\beta_1 GDP_{t-1} + \beta_2 CCI_{t} + \beta_3 GT_{t,i} + \epsilon_t \qquad  t =1,\dotsc,T \qquad  n =1,\dotsc,N$
```{r}
mod6<- lm(gdp ~ lag(gdp) + cci + google, data = Data_train)
summary(mod6)
sqrt(mean(mod6$residuals^2)) # IS 
forecast::accuracy(mod6) # IS 

##OOS
pred_mod6 <- predict(mod6, Data_test)
acc_oos6 <-forecast::accuracy(Data_test$gdp,pred_mod6)
acc_oos6

predictnew <- predict(mod6,)
```
#Summary results 

```{r}
stargazer::stargazer(mod1,mod2,mod3,mod4,mod5,mod6)
stargazer::stargazer(acc_oos5,acc_oos6)
```


#VAR model mit Varselect all 3 variables
```{r}
Yselect <- VARselect(Data_train[,c(1,2)],type = "const")   
#Yselect <- VARselect(Data[,4:6],type = "none") #lag 2      # computes information criteria
  lag <- Yselect$selection[1]  # AiC, Hq auch 2 , SC auch
  
lag 

VAR_est <- VAR(y = Data[,1:3], p = lag)
summary(VAR_est$varresult$gdp)
forecast::accuracy(VAR_est$varresult$gdp) # IS accuracy

library(Metrics)

#summary(VAR_est$varresult$gdp)$adj.r.squared
#summary(VAR_est$varresult$cci)$adj.r.squared
#summary(VAR_est$varresult$google)$adj.r.squared
forecasts <- predict(VAR_est,n.ahead = 3 )
forecasts

plot(forecasts)
stargazer(VAR_est$varresult)
```

### VAR(2) and 4 ... 
```{r}
dat <- ts(Data_train[,1:3], frequency = 4, start = c(2006, 1))

start=c(2017, 1)
end = c(2016,4)

trainingdata <- window(dat, end = end)
testdata <- window(dat, start=start)


v <- VAR(trainingdata, p=2) # change t0 2.!!!
summary(v$varresult$gdp)
p <- predict(v, n.ahead=3)

p$fcst$gdp

ts.plot(p$fcst$gdp)
#res <- residuals(v$varresult$gdp)
#fits <- fitted(v)
#RMSE <- sqrt(mean(res^2))

acc_is_VAR <-forecast::accuracy(trainingdata,v$varresult$gdp$fitted.values) # works!!! validated against 
###aber nicht test dat verwendet???predicted
acc_oos_VAR <-forecast::accuracy(testdata,p$fcst$gdp) # works!!! validated against test dat
#acc_oos_VAR <-forecast::accuracy(testdata,p$fcst$cci)
#acc_oos_VAR <-forecast::accuracy(testdata,p$fcst$google)

```


```{r}
library(vars)
var.AIC <- VAR(Data[,4:6],  type="none" , lag.max = 5, ic = c("AIC"))
var.SC <- VAR(Data[,4:6],  type="none" , lag.max = 5, ic = c("SC"))
var.AIC.c <- VAR(Data[,4:6],  type="const" , lag.max = 5, ic = c("AIC")) ## lag 2
var.SC.c <- VAR(Data[,4:6],  type="const" , lag.max = 5, ic = c("SC")) ## lag 1

AIC.woc <- cbind(AIC(var.AIC), BIC(var.AIC)) 
AIC.wc<- cbind(AIC(var.AIC.c), BIC(var.AIC.c)) 
SC.woc <- cbind(AIC(var.SC), BIC(var.SC)) 
SC.wc <- cbind(AIC(var.SC.c), BIC(var.SC.c)) 

MC.table <- rbind(AIC.woc, AIC.wc, SC.woc, SC.wc)
MC.table.names <- rbind("using AIC without constant", "using AIC with constant",
                        "using SC without constant","using SC with constant")  
rownames(MC.table)<- MC.table.names
colnames(MC.table) <- cbind("AIC", "BIC")

print(xtable::xtable(MC.table,caption="Model Choice Results",label="tab:mc"),
      sanitize.text.function=function(UR.table){UR.table},comment=FALSE)


stargazer(VAR_est$varresult)

```

# Residual analysis
```{r}
sum2 <- data.frame(
  VAR_est$varresult$gdp$residuals,
  VAR_est$varresult$cci$residuals,
  VAR_est$varresult$google$residuals)

adf.test(VAR_est$varresult$gdp$residuals) # stationary
adf.test(VAR_est$varresult$cci$residuals) #stationary
adf.test(VAR_est$varresult$google$residuals)#stationary
```

# Normality test
```{r}
Normtest <- normality.test(VAR_est) # H0: normality
print(Normtest)
plot(Normtest)
```


```{r}
library(car)
durbinWatsonTest(VAR_est$varresult$gdp)
durbinWatsonTest(varma$residuals)
```
# serial correlation check
```{r}
ser.test <- serial.test(VAR_est) # H0: no serial correlation
ser.test
```

#VAR model mit Varselect gdp and cci 
```{r}
Yselect_2 <- VARselect(Data_train[,4:5])               # computes information criteria
  lag <- Yselect_2$selection[1]  
 lag 
VAR_est_2 <- VAR(y = Data_train[,1:2], p = lag)

summary(VAR_est_2)
#summary(VAR_est$varresult$gdp)$adj.r.squared
#summary(VAR_est$varresult$cci)$adj.r.squared
#summary(VAR_est$varresult$google)$adj.r.squared
forecasts_2 <- predict(VAR_est_2,Data_test[,1:2])

plot(forecasts_2)

```

#VAR model mit Varselect gdp and google 
```{r}
Yselect_3 <- VARselect(Data_train[,c(1,3)])               # computes information criteria
  lag <- Yselect_3$selection[1]  
lag  
VAR_est_3 <- VAR(y = Data_train[,c(1,3)], p = lag)
summary(VAR_est_3)

#summary(VAR_est$varresult$gdp)$adj.r.squared
#summary(VAR_est$varresult$cci)$adj.r.squared
#summary(VAR_est$varresult$google)$adj.r.squared
forecasts_3 <- predict(VAR_est_3,Data_test[,c(1,3)],n.ahead = 3)
#accuracy(forecasts)

plot(forecasts_3)
```

# AR & VAR model Heik again mit selction criteria (AIC, autoarima, varselect)
```{r}
# AR(1) model 
arima <- auto.arima(Data[,"gdp"], trace = TRUE,  ic = c("aic")) #2,0,0 # lower RMSE 
#arima <- auto.arima(Data_train[,"gdp"], trace = TRUE,  ic = c("bic")) #1,0,0
summary(arima) # Ins sample RMSE! 

y_train <- forecast(arima, h = 3)$fitted # We make a forecast one hour ahead and we extract the fitted values from the object forecast.
x_train <- Data_train[,"gdp"]
rss <- sum((y_train - x_train) ** 2)
tss <- sum((x_train - mean(x_train)) ** 2)
R_squared <- 1 - rss/tss
paste(c("R-squared:", round(R_squared, 4)))

##### apply model to test set

#accuracy(cafe.test$fitted)
y_pred <- forecast(Data_test[,"gdp"], model = arima, h=3)$fitted # We call the forecast function passing the testing data through the ARIMA model fitted with the training data and we extract the fitted values.
y_test <- Data_test[,"gdp"]
sd_test <- sd(y_test)
RMSE <- rmse(y_test, y_pred)

MAE <- mae(y_test, y_pred)

rss <- sum((y_test - y_pred) ** 2)
tss <- sum((y_test - mean(y_test)) ** 2)
R_squared <- 1 - rss/tss

errors <- as.ts(y_test - y_pred)

adf.test(errors)



#arima.OOS <- Arima(Data_test[,"gdp"], model=arima)
#summary(arima.OOS)   # RMSE 5,06.

#pred <- predict(arima.OOS,n.ahead = 3) # same !
#fore <- forecast(arima.OOS,h=3) # same !
plot(forecast(y_pred,h=3)) # forecast 1Q  ahead!!! 

```
# AR(4) model wegen quarterly data
```{r}
AR_4 <- Arima(Data[,"gdp"], order=c(0,0,1))
summary(AR_4)

y_train <- forecast(AR_4, h = 3)$fitted # We make a forecast one hour ahead and we extract the fitted values from the object forecast.
x_train <- Data_train[,"gdp"]
rss <- sum((y_train - x_train) ** 2)
tss <- sum((x_train - mean(x_train)) ** 2)
R_squared <- 1 - rss/tss
paste(c("R-squared:", round(R_squared, 4)))


errors <- as.ts(y_train - x_train) # if whole set (MA(1)) and AR(2)...whole data 
adf.test(errors) # stationaryy 

##### apply model to test set

y_pred <- forecast(Data_test[,"gdp"], model = AR_4, h=3)$fitted # We call the forecast function passing the testing data through the ARIMA model fitted with the training data and we extract the fitted values.
y_test <- Data_test[,"gdp"]
sd_test <- sd(y_test)
RMSE <- rmse(y_test, y_pred)

MAE <- mae(y_test, y_pred)

rss <- sum((y_test - y_pred) ** 2)
tss <- sum((y_test - mean(y_test)) ** 2)
R_squared <- 1 - rss/tss

plot(forecast(y_pred,h=3))
autoplot(forecast(cafe.train))

errors <- as.ts(y_test - y_pred) # not stationary!! 

adf.test(errors) # data train (AR(2)) stationary, non stat for MA(1)
 
```
```{r}

arima <- auto.arima(Data[,"gdp"], trace = TRUE,  ic = c("aic")) #2,0,0 # lower RMSE 
summary(arima) # 001

arma1 <- arima(Data$gdp, order = c(1,0,1))
ar2ma1 <- arima(Data$gdp, order = c(2,0,1))
ar1 <- arima(Data$gdp, order = c(1,0,0))
ar2 <- arima(Data$gdp, order = c(2,0,0))
ma1 <- arima(Data$gdp, order = c(0,0,1))

AIC <- AIC(arma1, ar2ma1, ar1, ar2,ma1)
BIC<- BIC(arma1, ar2ma1, ar1, ar2,ma1)
ab<- cbind(AIC, BIC)

arima <- auto.arima(Data_train[,"gdp"], trace = TRUE,  ic = c("aic")) #2,0,0 # lower RMSE 
summary(arima) # 001

arma1 <- Arima(Data_train$gdp, order = c(1,0,1))
ar2ma1 <- arima(Data_train$gdp, order = c(2,0,1))
ar1 <- arima(Data_train$gdp, order = c(1,0,0))
ar2 <- arima(Data_train$gdp, order = c(2,0,0))
ma1 <- arima(Data_train$gdp, order = c(0,0,1))

AIC <- AIC(arma1, ar2ma1, ar1, ar2,ma1)
BIC<- BIC(arma1, ar2ma1, ar1, ar2,ma1)
ab<- cbind(AIC, BIC)
```


# Expanding window estimation instead of fixed test and train data set 
# average over all 
An expanding window works like this:
# Use the past 100 days worth of data to estimate a regression model.
Use the regression model to predict the stock price 1 day from now.
Use all of the observations including the predicted value for tomorrow (i.e. observations 1 through 101) to run a regression model.
Use this to predict the stock price 2 days from now.
Use all of the observations including the predicted values to run a regression model.
Use this to predict the stock price 3 days from now.
Repeat this until you have as many observations as you want to predict

not doing here...incorporate new prediction... i do many psequdo OOS forecasts 1 step ahead
estimate on 1:12, predict 13, incorporate new 13 in data and estimate on 1:13, and predict 14 ?... 

will keine expanding für ARIMA!! AR(1) ist ja nur BM und ich will prüfen ob google data auch oos preduíctive power hat ... cci ersetzen kann besser als Ar(1) ist oder arima..change eifnach exp_ols code into ar(...)

### ist noch kein forecast...

```{r}
expanding_window_OLS <- function(data, dep_var, start = 19){ # change to 12 
  expanding_OLS <- list() # empty vector
  predicted_OLS <- list()
  resid_OLS <- list()
  error_OLS <- c() 
  i <- 0
  for(t in start:nrow(data)){#t in 13:51
    i <- i+1
    expanding_OLS[[i]] <- lm(formula = model, data = data[1:(t-1),]) # start at 13-1 so 12! 
    resid_OLS[[i]] <- resid(expanding_OLS[[i]])
    predicted_OLS[[i]] <- predict(expanding_OLS[[i]],newdata = data[t,])#[t,])
    error_OLS[i]  <- as.numeric(predicted_OLS[[i]] - data[t,]) # anpassen je nach dem welchs
    Summary_OLS <- list(expanding_OLS,predicted_OLS,resid_OLS,error_OLS)
  }
  return(Summary_OLS)
}
```

# Frame for errors
```{r}



```



#model1 expanding estimation
```{r}
dep_var <- "gdp"
model = gdp ~ gdp_lag

expanding_OLS1 <- expanding_window_OLS(Data[2:63,], dep_var, start = 19)

#predictions
pred <- do.call(rbind.data.frame, expanding_OLS[[2]]) # NAS wegen lag! 
colnames(pred) <- c("value")
rownames(pred) <- Date_q_pred[2:51]
Date_q_pred <- Date_q[13:63]

pred <- as.ts(pred, start=c(2009,2), end = c(2021,3), frequency = 4)
ts.plot(pred)

### error in and OOS 
error_OLS1 <- expanding_OLS1[[4]]
error_OLS1 <-error_OLS1[!is.na(error_OLS1)]
MAE_OLS_OOS1 <- mean(abs(error_OLS1))
MAE_OLS_OOS1
RMSE_OLS_OOS1  <- sqrt(mean(error_OLS1^2)) 
RMSE_OLS_OOS1
MSE_OLS1 <- mean(error_OLS1^2) 
MSE_OLS1

# table of all MAE etc und die dann calledM AE_OLS_OOS on data frame und stargazer... 

# IS error terms----------------------------------------------------------------
# IS: If you are forecasting for an observation that was part of the data sample - it is in-sample forecast.
resid_OLS1 <- expanding_OLS1[[3]]
final_resid_OLS1 <- resid_OLS1[[length(resid_OLS1)]]

RMSE_OLS_IS1    <- sqrt(mean(final_resid_OLS1^2))
RMSE_OLS_IS1

```
#model2 again
```{r}
model = gdp ~ cci
expanding_OLS2 <- expanding_window_OLS(Data, dep_var, start = 19)

pred <- do.call(rbind.data.frame, expanding_OLS2[[2]]) 
colnames(pred) <- c("value")
rownames(pred) <- Date_q_pred
Date_q_pred <- Date_q[13:63]

pred <- as.ts(pred, start=c(2009,1), end = c(2021,3), frequency = 4)
ts.plot(pred)

### error IS? and OOS 

error_OLS2 <- expanding_OLS2[[4]]
error_OLS2 <-error_OLS2[!is.na(error_OLS2)]
MAE_OLS_OOS2 <- mean(abs(error_OLS2))
MAE_OLS_OOS2
RMSE_OLS_OOS2   <- sqrt(mean(error_OLS2^2)) 
RMSE_OLS_OOS2
MSE_OLS2 <- mean(error_OLS2^2) 
MSE_OLS2

# R-Sq 
actual <- Data[13:63,"gdp"]
rss <- sum((pred - actual) ^ 2)  ## residual sum of squares
tss <- sum((actual - mean(actual)) ^ 2)  ## total sum of squares
rsq <- 1 - rss/tss
rsq

# IS error terms----------------------------------------------------------------
# IS: If you are forecasting for an observation that was part of the data sample - it is in-sample forecast.
resid_OLS2 <- expanding_OLS2[[3]]
final_resid_OLS2 <- resid_OLS2[[length(resid_OLS2)]]

RMSE_OLS_IS2   <- sqrt(mean(final_resid_OLS2^2))
RMSE_OLS_IS2

# pred
plot(forecast(pred,h=3))
```

#model3 again
```{r}
model = gdp ~ google
expanding_OLS3 <- expanding_window_OLS(Data, dep_var, start = 19)

pred <- do.call(rbind.data.frame, expanding_OLS[[2]]) 
colnames(pred) <- c("value")
rownames(pred) <- Date_q_pred
Date_q_pred <- Date_q[13:63]

pred <- as.ts(pred, start=c(2009,1), end = c(2021,3), frequency = 4)
ts.plot(pred)

### error in and OOS 
error_OLS3 <- expanding_OLS3[[4]]
error_OLS3 <-error_OLS[!is.na(error_OLS3)]
MAE_OLS_OOS3 <- mean(abs(error_OLS3))
MAE_OLS_OOS3
RMSE_OLS_OOS3    <- sqrt(mean(error_OLS3^2)) 
RMSE_OLS_OOS3
MSE_OLS3 <- mean(error_OLS3^2) 
MSE_OLS3

# forecast pred on newly data how do i incporpare that??? 
colnames(Google_AT_qtrly) <- c("Date_q","time","google")

x <- predict(expanding_OLS[[1]][[51]],Google_AT_qtrly[64:65,]) # used last estimated model ... 

error_x  <- as.numeric(x - Google_AT_qtrly$google[64:65]) 
MAE_OLS_OOS <- mean(abs(error_x))
MAE_OLS_OOS
RMSE_OLS_OOS    <- sqrt(mean(error_x^2)) 
RMSE_OLS_OOS
MSE_OLS <- mean(error_x^2) 
MSE_OLS
# IS error terms----------------------------------------------------------------
# IS: If you are forecasting for an observation that was part of the data sample - it is in-sample forecast.
resid_OLS3 <- expanding_OLS3[[3]]
final_resid_OLS3 <- resid_OLS3[[length(resid_OLS3)]]

RMSE_OLS_IS3    <- sqrt(mean(final_resid_OLS3^2))
RMSE_OLS_IS3
```

#model4 again
```{r, warning=F}
model = gdp ~ gdp_lag + cci
expanding_OLS4 <- expanding_window_OLS(Data[2:63,], dep_var, start = 19)

#predictions
pred <- do.call(rbind.data.frame, expanding_OLS[[2]]) # NAS wegen lag! 
colnames(pred) <- c("value")
rownames(pred) <- Date_q_pred[2:51]
Date_q_pred <- Date_q[13:63]

pred <- as.ts(pred, start=c(2009,2), end = c(2021,3), frequency = 4)
ts.plot(pred)

# Errors
error_OLS4 <- expanding_OLS4[[4]]
error_OLS4 <-error_OLS4[!is.na(error_OLS)]
MAE_OLS_OOS4 <- mean(abs(error_OLS4))
MAE_OLS_OOS4
RMSE_OLS_OOS4  <- sqrt(mean(error_OLS4^2)) 
RMSE_OLS_OOS4
MSE_OLS4 <- mean(error_OLS4^2) 
MSE_OLS4

# IS error terms----------------------------------------------------------------
# IS: If you are forecasting for an observation that was part of the data sample - it is in-sample forecast.
resid_OLS4 <- expanding_OLS4[[3]]
final_resid_OLS4 <- resid_OLS4[[length(resid_OLS4)]]

RMSE_OLS_IS4   <- sqrt(mean(final_resid_OLS4^2))
RMSE_OLS_IS4
```

#model5 again
```{r, warning==F}
model = gdp ~ gdp_lag + google
expanding_OLS5 <- expanding_window_OLS(Data[2:63,], dep_var, start = 19)

#predictions
pred <- do.call(rbind.data.frame, expanding_OLS[[2]]) # NAS wegen lag! 
colnames(pred) <- c("value")
rownames(pred) <- Date_q_pred[2:51]
Date_q_pred <- Date_q[13:63]

pred <- as.ts(pred, start=c(2009,2), end = c(2021,3), frequency = 4)
ts.plot(pred)

# Errors
error_OLS5 <- expanding_OLS5[[4]]
error_OLS5 <-error_OLS5[!is.na(error_OLS5)]
MAE_OLS_OOS5 <- mean(abs(error_OLS5))
MAE_OLS_OOS5
RMSE_OLS_OOS5  <- sqrt(mean(error_OLS5^2)) 
RMSE_OLS_OOS5
MSE_OLS5 <- mean(error_OLS5^2) 
MSE_OLS5
# IS error terms----------------------------------------------------------------
# IS: If you are forecasting for an observation that was part of the data sample - it is in-sample forecast.
resid_OLS5 <- expanding_OLS5[[3]]
final_resid_OLS5 <- resid_OLS5[[length(resid_OLS)]]

RMSE_OLS_IS5    <- sqrt(mean(final_resid_OLS5^2))
RMSE_OLS_IS5
```

#model6 again
```{r, warning=F}
model = gdp ~ gdp_lag + cci + google
expanding_OLS6 <- expanding_window_OLS(Data[2:63,], dep_var, start = 19)

#predictions
pred <- do.call(rbind.data.frame, expanding_OLS[[2]]) # NAS wegen lag! 
colnames(pred) <- c("value")
rownames(pred) <- Date_q_pred[2:51]
Date_q_pred <- Date_q[13:63]

pred <- as.ts(pred, start=c(2009,2), end = c(2021,3), frequency = 4)
ts.plot(pred)

# Errors
error_OLS6 <- expanding_OLS6[[4]]
error_OLS6 <-error_OLS6[!is.na(error_OLS6)]
MAE_OLS_OOS6 <- mean(abs(error_OLS6))
MAE_OLS_OOS6
RMSE_OLS_OOS6  <- sqrt(mean(error_OLS6^2)) 
RMSE_OLS_OOS6
MSE_OLS6 <- mean(error_OLS6^2) 
MSE_OLS6

# IS error terms----------------------------------------------------------------
# IS: If you are forecasting for an observation that was part of the data sample - it is in-sample forecast.
resid_OLS6 <- expanding_OLS6[[3]]
final_resid_OLS6 <- resid_OLS6[[length(resid_OLS6)]]

RMSE_OLS_IS6    <- sqrt(mean(final_resid_OLS6^2))
RMSE_OLS_IS6
```

Summary results
```{r}
comparison_MAE_OOS <- rbind("MAE_OLS_OOS" = MAE_OLS_OOS1,MAE_OLS_OOS2,MAE_OLS_OOS3,MAE_OLS_OOS4,MAE_OLS_OOS5,MAE_OLS_OOS6)

comparison_RMSE_OOS <- rbind("RMSE_OLS_OOS" = RMSE_OLS_OOS1,RMSE_OLS_OOS2,RMSE_OLS_OOS3,RMSE_OLS_OOS4,RMSE_OLS_OOS5,RMSE_OLS_OOS6)

comparison_RMSE_IS <- rbind("RMSE_OLS_IS" = RMSE_OLS_IS1,RMSE_OLS_IS2,RMSE_OLS_IS3,RMSE_OLS_IS4,RMSE_OLS_IS5,RMSE_OLS_IS6)

 
comparison_OOS <- data.frame("MAE_OOS" = comparison_MAE_OOS,
                                        "RMSE_OOS" = comparison_RMSE_OOS, 
                                        "RMSE_IS" = comparison_RMSE_IS)

stargazer::stargazer(comparison_OOS,summary=FALSE, rownames=FALSE)
```



#ARIMA(2,0,0) expanding estimation
```{r}
Data$gdp_lag2 <- lag(Data$gdp_lag)

dep_var <- "gdp"
model = gdp ~ gdp_lag + gdp_lag2

expanding_OLS <- expanding_window_OLS(Data[3:63,], dep_var, start = 13)

#predictions
pred <- do.call(rbind.data.frame, expanding_OLS[[2]]) # NAS wegen lag! 
colnames(pred) <- c("value")
rownames(pred) <- Date_q_pred[3:51]
Date_q_pred <- Date_q[13:63]

pred <- as.ts(pred, start=c(2009,3), end = c(2021,3), frequency = 4)
ts.plot(pred)

### error in and OOS 
error_OLS <- expanding_OLS[[4]]
error_OLS <-error_OLS[!is.na(error_OLS)]
MAE_OLS_OOS <- mean(abs(error_OLS))
MAE_OLS_OOS
RMSE_OLS_OOS  <- sqrt(mean(error_OLS^2)) 
RMSE_OLS_OOS
MSE_OLS <- mean(error_OLS^2) 
MSE_OLS
# IS error terms----------------------------------------------------------------
# IS: If you are forecasting for an observation that was part of the data sample - it is in-sample forecast.
resid_OLS <- expanding_OLS[[3]]
final_resid_OLS <- resid_OLS[[length(resid_OLS)]]

RMSE_OLS_IS    <- sqrt(mean(final_resid_OLS^2))
RMSE_OLS_IS
```

#### VAR expanding window, same VAR as VAR select just expanding 

# create new dataset!!!
```{r}
# keep orginals ones though,...
Data_Var <-flag(Data[1:3], 1:2)
Data_Var <- cbind(Data[,1:3],Data_Var)## all have lag 2.... 

model= gdp ~ L1.gdp +L2.gdp + L1.cci +L2.cci +L1.google + L2.google

  #change "!! dependt on var names form flag.. 

expanding_OLS <- expanding_window_OLS(Data_Var[3:63,], dep_var, start = 13) # adjust start???
#predictions
pred <- do.call(rbind.data.frame, expanding_OLS[[2]]) # NAS wegen lag! 
colnames(pred) <- c("value")
rownames(pred) <- Date_q_pred[3:51]
Date_q_pred <- Date_q[13:63]

pred <- as.ts(pred, start=c(2009,3), end = c(2021,3), frequency = 4)
ts.plot(pred)

### error in and OOS 
error_OLS <- expanding_OLS[[4]]
error_OLS <-error_OLS[!is.na(error_OLS)]
MAE_OLS_OOS <- mean(abs(error_OLS))
MAE_OLS_OOS
RMSE_OLS_OOS  <- sqrt(mean(error_OLS^2)) 
RMSE_OLS_OOS
MSE_OLS <- mean(error_OLS^2) 
MSE_OLS
# IS error terms----------------------------------------------------------------
# IS: If you are forecasting for an observation that was part of the data sample - it is in-sample forecast.
resid_OLS <- expanding_OLS[[3]]
final_resid_OLS <- resid_OLS[[length(resid_OLS)]]

RMSE_OLS_IS    <- sqrt(mean(final_resid_OLS^2))
RMSE_OLS_IS
```


### as extension create consumer index.. later!! once written all maybe 

# write down all models  I want todo (Heik models, 4 lags quarterly data, and tests for lag length with arima and VAR models)

# do simple split OOS forecast and expanding OOS forecast
# adjust expanding window functions (for Var, arima)
# Forecasting with rest of the data... newdata = 2-3 obs?
# Robustness different aggregation,  LLOCV
#durbinWatsonTest, cumsum

#Extensions
```{r}
# different data aggregation?
# maybe policyy uncertainty index
# unemployment and inflation VAR
```


```{r}
ctrl <- trainControl(method = "LOOCV")

# lag problem again... easiest prob do to new data frame and add it as a variables
model1_CV <- train(gdp ~ gdp_lag, data = Data[2:63,], method = "lm", trControl = ctrl)
print(model1_CV)

model2_CV <- train(gdp ~ cci, data = Data, method = "lm", trControl = ctrl)
print(model2_CV)

model3_CV <- train(gdp ~ google, data = Data, method = "lm", trControl = ctrl)
print(model3_CV)

model4_CV <- train(gdp ~ gdp_lag + cci, data = Data[2:63,], method = "lm", trControl = ctrl)
print(model4_CV)

model5_CV <- train(gdp ~ gdp_lag + google, data = Data[2:63,], method = "lm", trControl = ctrl)
print(model5_CV)

model6_CV <- train(gdp ~ gdp_lag + google + cci, data = Data[2:63,], method = "lm", trControl = ctrl)
print(model6_CV)
```
