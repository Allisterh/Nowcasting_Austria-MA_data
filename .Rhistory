#' 1) updates all the keywords by downloading newest Google trends data.
#' 2) combines monthly, weekly, and daily frequencies.
#' 3) runs seasonal adjustment steps.
#' 4) combines all the keywords into one index using principal components.
#' 5) writes the produced index to a file
#'
#' @param keywords A vector of keyword names comprising the index.
#' @param geo A character vector denoting geographic region.
#' @param index_name The name given to the index.
#'
#' @examples
#' \dontrun{
#' keywords <- c( "Mango", "Zara", "H&M", "PKZ", "Blue Tomato","Dosenbach", "Schuhe kaufen", "Ochsner Schuhe")
#' proc_index(keywords, "ch", "clothing")
#' }
#' @export
proc_index <- function(keywords, geo, index_name) {
lapply(keywords, proc_keyword, geo = geo)
data <- read_keywords(keywords, geo = geo, id = "seas_adj")
# make sure all keywords have the same span
data <- data %>%
filter(time <= min(ts_summary(data)$end))
x_prcomp <- filter(ts_prcomp(data), id == "PC1") %>%
select(-id) %>%
ts_scale()
# determine PC sign based on average correlation with actual time series
values  <- mapply(getElement, split(data, data$keyword), "value")
corsign <- mean(cor(values, x_prcomp$value))
if(corsign < 0) {
x_prcomp$value <- -x_prcomp$value
}
# invert main index
if (index_name == "trendecon") {
x_prcomp$value <- -x_prcomp$value
}
write_keyword(x_prcomp, index_name, geo, "sa")
}
keyword_plot <- function(keyword = NULL, x = NULL, target = NULL, invert = FALSE, freq = "quarter") {
if (!is.null(keyword)) {
x <- ts_frequency(ts_gtrends(keyword = keyword, time = "2007-01-01 2020-04-05"), freq)
} else {
keyword <- "Series"
}
if (invert) (x$value <- -x$value)
x_seas <- ts_seas(x, x11 = "", outlier = NULL)
m <- seasonal::seas(ts_ts(x), x11 = "", outlier = NULL)
x_seas <- seasonal::final(m)
x_trend <- seasonal::trend(m)
op <- options(
tsbox.lwd = c(1, 2, 1, 1),
tsbox.col = c("red", "red", "grey", "blue"),
tsbox.lty = c("solid", "solid", "dashed", "solid")
)
ind <- ts_c(
orig = x,
seas = x_seas,
trend = x_trend
)
if (!is.null(target)) ind <- ts_c(ind, target)
dta <- ts_scale(ind)
ts_plot(dta, title = paste("Keyword:", keyword))
options(op) # restore defaults
}
# daily seasonal adjustment, using prophet
#
# seas_adj_file("Insolvenz")
proc_seas_adj <- function(keyword = "Insolvenz", geo = "AT") {
message("seasonal adjustment keyword: ", keyword)
tsbox::load_suggested("prophet")
data <- read_keyword(keyword, geo, "mwd")
# data <- tsbox::ts_tbl(AirPassengers)
df <- dplyr::rename(data, ds = time, y = value)
# financial crisis as oultier
# df[df$ds >= "2008-09-01" & df$ds <= "2009-12-31", 'y'] <- NA
# hack: prophet does not like to be imported
generated_holidays <- prophet::generated_holidays
assign("generated_holidays", prophet::generated_holidays, envir = globalenv())
m <-
# prophet(holidays = holidays, daily.seasonality = FALSE) %>%
prophet::prophet(daily.seasonality = FALSE) %>%
prophet::add_country_holidays(country_name = toupper(geo)) %>%
prophet::fit.prophet(df)
# forecast <- predict(m, df)
# prophet_plot_components(m, forecast)
z <- predict(m)
sa <-
z %>%
transmute(time = as.Date(ds), trend, seas_comp = additive_terms) %>% # additive_terms = yhat - trend,
left_join(data, by = "time") %>%
rename(orig = value) %>%
mutate(seas_adj = orig - seas_comp) %>%
ts_long()
write_keyword(sa, keyword, geo, "sa")
}
knitr::opts_chunk$set(echo = TRUE)
Wohnbaukredit <- gtrends("Wohnbaukredit", time = "today+5-y", geo = "AT") # last five years (default)
library(gtrends)
install.packages("gtrendsR")
library(gtrendsR)
Wohnbaukredit <- gtrends("Wohnbaukredit", time = "today+5-y", geo = "AT") # last five years (default)
View(Wohnbaukredit)
library(trendecon)
x <- ts_gtrends("Wohnbaukredit", geo = "AT")
library(trendecon)
x <- ts_gtrends("Wohnbaukredit", geo = "AT")
x <- ts_gtrends("Konjunkturentwicklung", geo = "AT")
x <- ts_gtrends("Corona", geo = "AT")
# install.packages("remotes")
remotes::install_github("trendecon/trendecon")
# install.packages("remotes")
remotes::install_github("trendecon/trendecon")
ibrary(trendecon)
library(trendecon)
x <- ts_gtrends("", geo = "AT")
gt_data <- ts_gtrends(
keyword = c("Wirtschaftswachstum", "Rohstoffpreise", "Baufinanzierung", "Kredit", "Baubewilligung"),
geo     = "AT")
x <- ts_gtrends("cinema", geo = "AT")
library(trendecon)
x <- ts_gtrends("cinema", geo = "AT")
ts_gtrends_mwd("cinema", geo = "CH")
x <- ts_gtrends("cinema", geo = "CH")
x <- ts_gtrends("cinema", geo = "AT", low_search_volume = FALSE,
cookie_url = "http://trends.google.com/Cookies/NID")
x <- ts_gtrends("cinema", geo = "AT", low_search_volume = FALSE)
knitr::opts_chunk$set(echo = TRUE)
# schauen welche ich wirklich brauche!
#rm(list=ls())
library(readr)
library(readxl)
library(dplyr)
library(tidyverse)
library(ggplot2)
library(Metrics)
library(gtrendsR)
library(tsbox)
library(zoo)
library(tseries)
library(tempdisagg)
library(x12)
library(trendecon)
library(pls)
library(prophet)
library(glmnet)
library(reshape2)
library(midasr)
library(lubridate)
library(caret)
getwd()
setwd("/Users/annevalder/Desktop/UNI /WU WIEN/SoSe_21/MA/data/Rcode")
#### GDP ####
GDP_qtrly <- read_csv("GDP_AT_Q12006.csv")[64:126,6:7] # unnötige columns weg und nur AT daten!
colnames(GDP_qtrly)[colnames(GDP_qtrly) %in% c("TIME", "Value")] <- c("QDate", "Value")
#### Check data for stationarity and difference
GDP_GR_diff <- diff(GDP_qtrly$Value)
adf.test(GDP_qtrly$Value) # not stationary growth rates!!!
adf.test(GDP_diff) # differnce of groeth rates is stationary!
adf.test(GDP_GR_diff) # differnce of groeth rates is stationary!
adf.test(GDP_qtrly$Value) # not stationary growth rates!!!
### change to TS objrects!
GDP_ts = ts(GDP_qtrly$Value,start=c(2006), end = c(2021), frequency = 4)
pp.test(GDP_qtrly$Value) # statioanry
kpss.test(GDP_qtrly$Value) # statioanry
acf(GDP_qtrly$Value)
pacf(GDP_AT$logValue)
pacf(GDP_qtrly$Value) # suggests AR(1) model!!
auto.arima(GDP_qtrly$Value, trace = TRUE,  ic = c( "aic"))  ## sugessts a MA(1) model !!
auto.arima(GDP_qtrly$Value, trace = TRUE,  ic = c( "aic"))  ## sugessts a MA(1) model !!
ts.plot(GDP_ts)
library(forecast)
auto.arima(GDP_qtrly$Value, trace = TRUE,  ic = c( "aic"))  ## sugessts a MA(1) model !!
auto.arima(GDP_qtrly$Value, trace = TRUE,  ic = c( "bic"))  ## sugessts a MA(1) model !!
auto.arima(GDP_qtrly$Value, trace = TRUE,  ic = c( "aic"))  ## sugessts a MA(1) model !!
auto.arima(GDP_GR_diff, trace = TRUE,  ic = c( "aic"))  ## sugessts a MA(1) model !!
auto.arima(GDP_GR_diff, trace = TRUE,  ic = c( "bic"))  ## sugessts a MA(1) model !!
Google_AT_daily <- read.csv("https://raw.githubusercontent.com/trendecon/data/master/data/at/trendecon_sa.csv")
Google_AT_daily <- read.csv("https://raw.githubusercontent.com/trendecon/data/master/data/at/trendecon_sa.csv")
Google_AT_daily <-  data.frame(Google_AT_daily)
colnames(Google_AT_daily)[colnames(Google_AT_daily) %in% c("time", "value")] <- c("Date", "Value")
adf.test(Google_AT_daily$Value) ## stationary 0.01
acf(Google_AT_daily$Value)
difftest <- diff(Google_AT_daily$Value)
difftest <- diff(Google_AT_daily$Value)
acf(difftest)
adf.test(difftest)
kpss.test(Google_AT_daily$Value)
kpss.test(difftest)
difftest <- diff(Google_AT_daily$Value)
acf(Google_AT_daily$Value)
ar1 <- arima(GDP_ts, order = c(1,0,0))
ar1 <- arima(GDP_ts, order = c(1,0,0))
ar2 <- arima(GDP_ts, order = c(2,0,0))
ar3 <- arima(GDP_ts, order = c(3,0,0))
ar4 <- arima(GDP_ts, order = c(4,0,0))
AIC <- AIC(ar1, ar2, ar3, ar4)
AIC <- AIC(ar1, ar2, ar3, ar4)
BIC <- BIC(ar1, ar2, ar3, ar4)
View(BIC)
View(AIC)
auto.arima(Data$GDPGR, trace = TRUE)
auto.arima(Data$GDP, xreg = x ,trace = TRUE)
auto.arima(GDP_qtrly$Value, trace = TRUE)
ar2 <- arima(GDP_ts, order = c(0,0,0))
ar3 <- arima(GDP_ts, order = c(0,0,1))
AIC <- AIC(ar1, ar2, ar3, ar4)
View(AIC)
BIC <- BIC(ar1, ar2, ar3, ar4)
MA <- arima(GDP_ts, order = c(0,0,1))
MA$var.coef
MA$coef
MA$aic
# schauen welche ich wirklich brauche!
#rm(list=ls())
library(readr)
library(readxl)
library(dplyr)
library(tidyverse)
library(ggplot2)
library(Metrics)
library(gtrendsR)
library(tsbox)
library(zoo)
library(tseries)
library(tempdisagg)
library(x12)
library(trendecon)
library(pls)
library(prophet)
library(glmnet)
library(reshape2)
library(midasr)
library(lubridate)
library(caret)
library(forecast)
getwd()
#### GDP ####
GDP_qtrly <- read_csv("GDP_AT_Q12006.csv")[64:126,6:7] # unnötige columns weg und nur AT daten!
colnames(GDP_qtrly)[colnames(GDP_qtrly) %in% c("TIME", "Value")] <- c("QDate", "Value")
#### Check data for stationarity and difference
GDP_GR_diff <- diff(GDP_qtrly$Value)
adf.test(GDP_qtrly$Value) # not stationary growth rates!!!
adf.test(GDP_GR_diff) # differnce of groeth rates is stationary!
### change to TS objrects!
GDP_ts = ts(GDP_qtrly$Value,start=c(2006), end = c(2021), frequency = 4)
### change to TS objrects!
GDP_ts = ts(GDP_qtrly$Value,start=c(2006), end = c(2022), frequency = 4)
pp.test(GDP_qtrly$Value) # statioanry
pp.test(GDP_qtrly$Value) # statioanry
kpss.test(GDP_qtrly$Value) # statioanry
pp.test(GDP_qtrly$Value) # statioanry
adf.test(GDP_qtrly$Value) # not stationary growth rates!!!
adf.test(GDP_qtrly$Value) # not stationary growth rates!!! , H0 not stat
pp.test(GDP_qtrly$Value) # statioanry H0 not stat
pp.test(GDP_qtrly$Value) # statioanry H0 not stat
adf.test(GDP_qtrly$Value) # not stationary growth rates!!! , H0 not stat, cannot reject that is stationary,null hypothesis (not stat) can not be rejected -
pp.test(GDP_qtrly$Value) # statioanry H0 not stat
kpss.test(GDP_qtrly$Value) # statioanry, h0  stationarity
#opposite of ADF: Null Hypothesis: The process is trend stationary.
kpss.test(GDP_qtrly$Value) # statioanry, h0 stationarity, cannot reject the H0 cannot reject that is stationary, so is stationary
adf.test(GDP_qtrly$Value) # not stationary growth rates!!! , H0 not stat, cannot reject that is not stationary,null hypothesis (not stat) can not be rejected -
#opposite of ADF: Null Hypothesis: The process is trend stationary.
kpss.test(GDP_qtrly$Value) # statioanry, h0 stationarity, cannot reject the H0 cannot reject that is stationary, so is stationary
acf(GDP_qtrly$Value)
library(urca)
ur.kpss()
ur.kpss(GDP_qtrly$Value)
ur.kpss(GDP_qtrly$Value)
ndiffs(GDP_qtrly$Value)
?adf.test
#Case 3: KPSS indicates stationarity and ADF indicates non-stationarity - The series is trend stationary. Trend needs to be removed to make series strict stationary. The detrended series is checked for stationarity.
diffTS <- diff(GGDP_ts)
#Case 3: KPSS indicates stationarity and ADF indicates non-stationarity - The series is trend stationary. Trend needs to be removed to make series strict stationary. The detrended series is checked for stationarity.
diffTS <- diff(GDP_ts)
ts.plot(diffTS)
ts.plot(GDP_ts)
ts.plot(diffTS)
ts.plot(GDP_ts)
decompose(GDP_AT$Value)
decompose(GDP_qtrly$Value)
decompose(GDP_ts)
plot(decompose(GDP_ts))
lag.plot(GDP_qtrly$Value)
lag.plot(GDP_qtrly$Value,do.lines=FALSE, pch=20)
lag.plot(GDP_qtrly$Value,do.lines=FALSE)
, pch=20
lag.plot(GDP_qtrly$Value,do.lines=FALSE, pch=20)
cor(GDP_qtrly)
cor(GDP_qtrly$Value,lag(GDP_qtrly$Value))
lag1 <-lag(GDP_qtrly$Value
cor(GDP_qtrly$Value,lag(GDP_qtrly$Value))
lag1 <-lag(GDP_qtrly$Value)
cor(GDP_qtrly$Value,lag1)
cor.test(GDP_qtrly$Value,lag1)
acf(GDP_qtrly$Value)
pacf(GDP_qtrly$Value) # suggests AR(1) model!!
tsdisplay(GDP_ts, points=FALSE)
acf(GDP_qtrly$Value) #can also refer stationarity fro this!
abs(polyroot(c(1,0.2,-0.15)))
modelols_Google <- lm(GDP_qtrly$Value ~ lag(GDP_qtrly$Value))
summary(modelols_Google)
abs(polyroot(c(1,-0.2963)))
abs(polyroot(c(0.4115,-0.2963)))
fit <- auto.arima(GDP_GR_diff, trace = TRUE,  ic = c("aic"))  ## sugessts a MA(1) model !!
fit <- auto.arima(GDP_qtrly$Value, trace = TRUE,  ic = c("aic"))  ## sugessts a MA(1) model !!
tsdisplay(resid(fit))
round(accuracy(modelols_Google(fit, h=14), btest),3)
round(accuracy(forecast(modelols_Google, h=14), btest),3)
CCI_mntly<- read_xlsx("~/Desktop/Uni/WU WIEN/SoSe_21/MA/data/CCI.xlsx",sheet = "CONSUMER MONTHLY")[253:444,c(1,297)] # 297 ist Spalte KK - total index!
CCI_mntly <- CCI_mntly %>% data.frame()
colnames(CCI_mntly)[colnames(CCI_mntly) %in% c("...1", "CONS.AT.TOT.COF.BS.M")] <- c("Date", "Value")
CCI_mntly$Value <- as.numeric(CCI_mntly$Value)
#CCI_mntly_ts <- ts(CCI_mntly$Value)
adf.test(CCI_mntly$Value) # not stationary!
CCI_diff <- diff(CCI_mntly$Value)
CCI_mntly <- CCI_mntly %>% data.frame()
adf.test(CCI_diff) ## differneced then stationary!!!!
#### Convert Monthly data into quarterly data!
##1) Temporal Aggregation!
CCI_mntly <- arrange(CCI_mntly, Date)
CCI_mntly$QDate <- as.yearqtr(CCI_mntly$Date)
CCI_mntly$QDate <- as.character(CCI_mntly$QDate)
CCI_mntly$QDate[CCI_mntly$QDate == "2021 Q4"] <- "2021 Q3"
#CI_mntly$QDate <- as.yearqtr(CCI_mntly$QDate)
CCI_qtrly <- CCI_mntly %>% group_by(QDate) %>%
summarise_all(mean)
adf.test(CCI_qtrly$Value) # 0.01
acf(CCI_qtrly$Value)
pacf(CCI_qtrly$Value)
Google_AT_daily <- read.csv("https://raw.githubusercontent.com/trendecon/data/master/data/at/trendecon_sa.csv")
colnames(Google_AT_daily)[colnames(Google_AT_daily) %in% c("time", "value")] <- c("Date", "Value")
adf.test(Google_AT_daily$Value) ## stationary 0.01
acf(Google_AT_daily$Value)
pacf(Google_AT_daily$Value)
Google_AT_daily$Date <- as.Date(Google_AT_daily$Date)
Google_AT_daily <- arrange(Google_AT_daily, Date)
Google_AT_daily$QDate <- as.yearqtr(Google_AT_daily$Date)
Google_AT_daily$QDate  <- as.character(Google_AT_daily$QDate)
Google_AT_daily$QDate[Google_AT_daily$QDate == "2022 Q1"] <- "2021 Q3"
Google_AT_daily$QDate[Google_AT_daily$QDate == "2021 Q4"] <- "2021 Q3"
Google_AT_daily$QDate <- as.yearqtr(Google_AT_daily$QDate)
Google_AT_qtrly <- Google_AT_daily %>% group_by(QDate) %>%
summarise_all(mean)
adf.test(Google_AT_qtrly$Value) # stationary at 5%
### 2) Select the last day of the artificial Quarter!
#systematic sampling
acf(Google_AT_qtrly$Value) ## lag(4)
acf(Google_AT_daily$Value) # stat
pacf(Google_AT_qtrly$Value) ## lag(4)
### change to TS objrects!
GDP_ts = ts(GDP_qtrly$Value,start=c(2006), end = c(2022), frequency = 4)
ar1 <- arima(GDP_ts, order = c(1,0,0)) # get 260 als AIC
ar2 <- arima(GDP_ts, order = c(0,0,0))
ar3 <- arima(GDP_ts, order = c(0,0,1)) #g gets alsi here bezzer resluts
ar4 <- arima(GDP_ts, order = c(4,0,0))
ar5 <- arima(GDP_ts, order = c(5,0,0))
ar6 <- arima(GDP_ts, order = c(6,0,0))
ar7 <- arima(GDP_ts, order = c(7,0,0))
ar8 <- arima(Data$GDPGR, order = c(8,0,0))
ar9 <- arima(Data$GDPGR, order = c(10,0,0))
auto.arima(GDP_qtrly$Value, trace = TRUE)  # gets 280 als AIC....
AIC <- AIC(ar1, ar2, ar3, ar4)
View(AIC)
shiny::runApp('~/Desktop/Uni/WU WIEN/SoSe_21/MA/MA')
knitr::opts_chunk$set(echo = TRUE)
remotes::install_local()   # build the package, only do once
gtrendecon::proc_all()
remotes::install_local()   # build the package, only do once
library(gtrendecon)
keywords <- c("Wirtschaftskrise", "Kurzarbeit", "arbeitslos", "Insolvenz")
remotes::install_local()   # build the package, only do once
remotes::install_local()   # build the package, only do once
library(trendecon)
remotes::install_local()   # build the package, only do once
gtrendecon::proc_all()
gtrendecon::proc_all()
install.packages("gtrendecon")
detach("package:gtrendsR", unload = TRUE)
library(gtrendsR)
knitr::opts_chunk$set(echo = TRUE)
# remotes::install_local()   # build the package, only do once
gtrendecon::proc_all()
library(trendecon)
trendecon::proc_all("/Users/annevalder/Desktop/Uni/WU WIEN/SoSe_21/MA/GIT")
remotes::install_local("/Users/annevalder/Desktop/Uni/WU WIEN/SoSe_21/MA/GIT")   # build the package, only do once
?remotes::install_local()
remotes::install_local(gtrendecon)   # build the package, only do once
remotes::install_local("gtrendecon")   # build the package, only do once
trendecon::proc_all("/Users/annevalder/Desktop/Uni/WU WIEN/SoSe_21/MA/GIT")
trendecon::proc_all("https://github.com/anneval/MA")
trendecon::proc_trendecon_at("https://github.com/anneval/MA")
trendecon::proc_trendecon_at()
trendecon::proc_trendecon_at()
getwd()
keywords <- c("Wirtschaftskrise", "Kurzarbeit", "arbeitslos", "Insolvenz")
lapply(keywords, proc_keyword)
getOption("path_trendecon")
getAnywhere()
getwd()
?trendecon::read_keywords()
data <- read_keywords(keywords,geo = "AT", id = "seas_adj")
#trendecon::proc_all("https://github.com/anneval/MA")
#trendecon::proc_trendecon_at()
setwd("/Users/annevalder/Desktop/Uni/WU WIEN/SoSe_21/MA")
lapply(keywords, proc_keyword)
data <- read_keywords(keywords,geo = "AT", id = "seas_adj")
#trendecon::proc_all("https://github.com/anneval/MA")
#trendecon::proc_trendecon_at()
setwd("/Users/annevalder/Desktop/Uni/WU WIEN/SoSe_21/MA/GIT")
data <- read_keywords(keywords,geo = "AT", id = "seas_adj")
proc_keyword_init("Wirtschaftskrise","AT")
proc_keyword_init("Kurzarbeit","AT")
proc_keyword_init("arbeitslos","AT")
proc_keyword_init("arbeitslos","AT")
x
1+1
proc_keyword_init("Insolvenz","AT")#bankruptcy
1+1
keywords <- c("Wirtschaftskrise", "Kurzarbeit", "arbeitslos")
data <- read_keywords(keywords,geo = "AT", id = "seas_adj")
lapply(keywords, proc_keyword) # do stepwise?
getwd()
lapply(keywords, proc_keyword) # do stepwise?
setwd("/Users/annevalder/Desktop/Uni/WU WIEN/SoSe_21/MA/GIT/raw")
lapply(keywords, proc_keyword) # do stepwise?
?grep
?list.files
?path_raw
# ORSTEPWISE
path_raw
# ORSTEPWISE
getwd(path_raw)
# ORSTEPWISE
getwd()
setwd("/Users/annevalder/Desktop/Uni/WU WIEN/SoSe_21/MA/GIT/raw")
# ORSTEPWISE
getwd()
# ORSTEPWISE
getwd()
setwd("/Users/annevalder/Desktop/Uni/WU WIEN/SoSe_21/MA/GIT/raw")
# ORSTEPWISE
getwd()
setwd("/Users/annevalder/Desktop/Uni/WU WIEN/SoSe_21/MA/GIT/raw")
lapply(keywords, proc_keyword) # do stepwise?
proc_keyword("Wirtschaftskrise","AT")
trendecon::path_keyword()
?trendecon::path_keyword()
path_keyword("/Users/annevalder/Desktop/Uni/WU WIEN/SoSe_21/MA/GIT/raw")
lapply(keywords, proc_keyword) # do stepwise?
proc_keyword("Wirtschaftskrise","AT")
path_trendecon("data-raw")
proc_keyword("Wirtschaftskrise","AT")
path_trendecon("raw")
proc_keyword("Wirtschaftskrise","AT")
path_raw <- function(...) {
path_trendecon("raw", ...)
}
path_raw()
proc_keyword("Wirtschaftskrise","AT")
path_trendecon("data-raw")
geo ="AT"
proc_keyword("Wirtschaftskrise","AT")
proc_keyword("Wirtschaftskrise","AT")
?path_draws
??path_draws
path_trendecon
?path_trendecon
path_trendecon("/Users/annevalder/Desktop/Uni/WU WIEN/SoSe_21/MA/GIT/raw)
path_trendecon("/Users/annevalder/Desktop/Uni/WU WIEN/SoSe_21/MA/GIT/raw")
path_trendecon("/Users/annevalder/Desktop/Uni/WU WIEN/SoSe_21/MA/GIT/raw")
proc_keyword("Wirtschaftskrise","AT")
proc_keyword("arbeitslos","AT")
proc_keyword("arbeitslos","at")
files_indicator <- grep(keyword,
list.files(path_raw(tolower(geo))),
value = TRUE,
fixed = TRUE)
keyword <- c("Wirtschaftskrise", "Kurzarbeit", "arbeitslos") #Insolvenz
files_indicator <- grep(keyword,
list.files(path_raw(tolower(geo))),
value = TRUE,
fixed = TRUE)
proc_keyword("Wirtschaftskrise","AT")
geo ="AT"
files_indicator <- grep(keyword,
list.files(path_raw(tolower(geo))),
value = TRUE,
fixed = TRUE)
files_indicator_raw <- grep(keyword,
list.files(path_draws(tolower(geo))),
value = TRUE,
fixed = TRUE)
path_draws <- function(...) {
path_trendecon("indicator_raw", ...)
}
files_indicator_raw <- grep(keyword,
list.files(path_draws(tolower(geo))),
value = TRUE,
fixed = TRUE)
View(path_draws)
path_raw"/Users/annevalder/Desktop/Uni/WU WIEN/SoSe_21/MA/GIT/raw"
path_raw"/Users/annevalder/Desktop/Uni/WU WIEN/SoSe_21/MA/GIT/raw")
path_raw("/Users/annevalder/Desktop/Uni/WU WIEN/SoSe_21/MA/GIT/raw")
files_indicator <- grep(keyword,
list.files(path_raw(tolower(geo))),
value = TRUE,
fixed = TRUE)
files_indicator_raw <- grep(keyword,
list.files(path_draws(tolower(geo))),
value = TRUE,
fixed = TRUE)
proc_keyword("Wirtschaftskrise","AT")
proc_keyword("Wirtschaftskrise","AT")
